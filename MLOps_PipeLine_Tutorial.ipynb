{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SUuzfpMu0Tf"
      },
      "source": [
        "# Step 1: Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LS0TPRKuRYg2"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.datasets import load_breast_cancer, load_iris\n",
        "import pandas as pd\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vFnk_03vBPd"
      },
      "source": [
        "# Step 2: Load and prepare data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Muo4W_BlRpAy"
      },
      "outputs": [],
      "source": [
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO2nF9M-vEI-"
      },
      "source": [
        "# Step 3: Define feature engineering steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yEWC6u4VRq_O"
      },
      "outputs": [],
      "source": [
        "# Example column names (assuming numerical features only for simplicity)\n",
        "numerical_features = data.feature_names\n",
        "categorical_features = []  # Add categorical feature names if any\n",
        "\n",
        "# Define transformers for numerical and categorical features\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C1RT0FLvLoX"
      },
      "source": [
        "# Step 4: Create and define the pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DoVBe4zDRssO"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLaCINaSvNKg"
      },
      "source": [
        "# Step 5: Split data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ihYABJ33RuBW"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCGfCykGvP-_"
      },
      "source": [
        "# Step 6: Fit the pipeline and evaluate using cross-validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy2ARFscRv57",
        "outputId": "08de19e2-9b46-49d9-9e44-8f62b86a6feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores: [0.95833333 1.         0.83333333 1.         0.95833333]\n",
            "Mean cross-validation score: 0.95\n"
          ]
        }
      ],
      "source": [
        "# Fit the pipeline on training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Perform cross-validation on training data\n",
        "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(f'Cross-validation scores: {cv_scores}')\n",
        "print(f'Mean cross-validation score: {cv_scores.mean():.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zonh0LtFvTSy"
      },
      "source": [
        "# Step 7: Evaluate on test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J-k8351W1fb",
        "outputId": "05725e3a-2477-4b10-b411-5b0a2951d74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Predict and evaluate on test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "accuracy = pipeline.score(X_test, y_test)\n",
        "print(f'Test accuracy: {accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqBMapn6vVp2"
      },
      "source": [
        "# Step 8: Save the trained pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVNjvVdqXCbB",
        "outputId": "39128674-eacc-427a-a8d5-a7c12b69f08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to trained_pipeline.pkl\n"
          ]
        }
      ],
      "source": [
        "# Save the pipeline to a file\n",
        "joblib_file = 'trained_pipeline.pkl'\n",
        "joblib.dump(pipeline, joblib_file)\n",
        "print(f'Model saved to {joblib_file}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg2djIJVvbCV"
      },
      "source": [
        "# Step 9: Load the trained pipeline (when needed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hkT22BmuYja",
        "outputId": "ddccadb5-ac2f-4b50-9dd3-77bc4c0eaa0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pipeline test accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Load the pipeline from the file\n",
        "loaded_pipeline = joblib.load(joblib_file)\n",
        "\n",
        "# Use the loaded pipeline to make predictions\n",
        "loaded_pipeline_predictions = loaded_pipeline.predict(X_test)\n",
        "loaded_pipeline_accuracy = loaded_pipeline.score(X_test, y_test)\n",
        "print(f'Loaded pipeline test accuracy: {loaded_pipeline_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 10: Inference with custom input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yScJvpkk0jhF",
        "outputId": "9eb3954b-000e-4113-8e0d-e47edd83352e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions for new data: [0 2]\n"
          ]
        }
      ],
      "source": [
        "# New data for prediction (replace this with your own data)\n",
        "new_data = pd.DataFrame({\n",
        "    'sepal length (cm)': [5.1, 6.2],\n",
        "    'sepal width (cm)': [3.5, 3.4],\n",
        "    'petal length (cm)': [1.4, 5.4],\n",
        "    'petal width (cm)': [0.2, 2.3]\n",
        "})\n",
        "\n",
        "# Predict using the loaded pipeline\n",
        "predictions = loaded_pipeline.predict(new_data)\n",
        "print(f'Predictions for new data: {predictions}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
